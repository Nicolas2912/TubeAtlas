"""
FastAPI server for TubeAtlas Knowledge Graph API.

This server provides endpoints to serve knowledge graph data generated by
the kg_builder_langchain.py module.
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Optional

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn

# Initialize FastAPI app
app = FastAPI(
    title="TubeAtlas Knowledge Graph API",
    description="API for serving knowledge graph data extracted from YouTube transcripts",
    version="1.0.0"
)

# Add CORS middleware to allow frontend requests
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173", "http://localhost:4173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Data directory path
DATA_DIR = Path("data")

# Available datasets mapping
DATASET_FILES = {
    "bryanjohnson": "complete_kg_langchain_bryanjohnson.json",
    "andreykarpathy": "complete_kg_langchain_AndrejKarpathy.json",
    "example": "example_kg_langchain.json"
}

@app.get("/")
async def root():
    """Root endpoint with API information."""
    return {
        "message": "TubeAtlas Knowledge Graph API",
        "version": "1.0.0",
        "endpoints": {
            "/api/kg/{dataset}": "Get knowledge graph for specific dataset",
            "/api/datasets": "List available datasets",
            "/health": "Health check endpoint"
        }
    }

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "message": "API is running"}

@app.get("/api/datasets")
async def get_datasets():
    """Get list of available datasets."""
    available_datasets = []
    
    for dataset_id, filename in DATASET_FILES.items():
        file_path = DATA_DIR / filename
        file_exists = file_path.exists()
        file_size = file_path.stat().st_size if file_exists else 0
        
        available_datasets.append({
            "id": dataset_id,
            "filename": filename,
            "exists": file_exists,
            "size_bytes": file_size,
            "path": str(file_path)
        })
    
    return {
        "datasets": available_datasets,
        "count": len(available_datasets)
    }

@app.get("/api/kg/{dataset}")
async def get_knowledge_graph(dataset: str):
    """
    Get knowledge graph data for a specific dataset.
    
    Args:
        dataset: The dataset identifier (e.g., 'bryanjohnson', 'andreykarpathy')
        
    Returns:
        JSON containing the knowledge graph triples
        
    Raises:
        HTTPException: If dataset not found or file doesn't exist
    """
    # Check if dataset is supported
    if dataset not in DATASET_FILES:
        raise HTTPException(
            status_code=404, 
            detail=f"Dataset '{dataset}' not found. Available datasets: {list(DATASET_FILES.keys())}"
        )
    
    # Get file path
    filename = DATASET_FILES[dataset]
    file_path = DATA_DIR / filename
    
    # Check if file exists
    if not file_path.exists():
        raise HTTPException(
            status_code=404,
            detail=f"Knowledge graph file not found: {filename}. Please generate the knowledge graph first using kg_builder_langchain.py"
        )
    
    try:
        # Load and return the knowledge graph data
        with open(file_path, 'r', encoding='utf-8') as f:
            kg_data = json.load(f)
        
        # Add metadata
        file_stats = file_path.stat()
        response_data = {
            **kg_data,
            "metadata": {
                "dataset": dataset,
                "filename": filename,
                "file_size_bytes": file_stats.st_size,
                "last_modified": file_stats.st_mtime,
                "triple_count": len(kg_data.get("triples", [])) if "triples" in kg_data else 0
            }
        }
        
        return response_data
        
    except json.JSONDecodeError as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error parsing knowledge graph file: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error loading knowledge graph: {str(e)}"
        )

@app.get("/api/kg/{dataset}/stats")
async def get_knowledge_graph_stats(dataset: str):
    """
    Get statistics for a knowledge graph dataset.
    
    Args:
        dataset: The dataset identifier
        
    Returns:
        JSON containing statistics about the knowledge graph
    """
    # Get the knowledge graph data
    kg_data = await get_knowledge_graph(dataset)
    triples = kg_data.get("triples", [])
    
    if not triples:
        return {"message": "No triples found in dataset"}
    
    # Calculate statistics
    subjects = set()
    objects = set()
    predicates = set()
    predicate_counts = {}
    
    for triple in triples:
        subject = triple.get("subject", "")
        predicate = triple.get("predicate", "")
        obj = triple.get("object", "")
        
        subjects.add(subject)
        objects.add(obj)
        predicates.add(predicate)
        
        predicate_counts[predicate] = predicate_counts.get(predicate, 0) + 1
    
    # Get unique entities (subjects âˆª objects)
    entities = subjects.union(objects)
    
    # Sort predicates by frequency
    top_predicates = sorted(predicate_counts.items(), key=lambda x: x[1], reverse=True)
    
    return {
        "dataset": dataset,
        "total_triples": len(triples),
        "unique_entities": len(entities),
        "unique_subjects": len(subjects),
        "unique_objects": len(objects),
        "unique_predicates": len(predicates),
        "top_predicates": top_predicates[:10],  # Top 10 most common predicates
        "predicate_distribution": predicate_counts
    }

if __name__ == "__main__":
    # Run the server
    print("Starting TubeAtlas Knowledge Graph API server...")
    print("API will be available at: http://localhost:8000")
    print("API documentation at: http://localhost:8000/docs")
    print("Available datasets:", list(DATASET_FILES.keys()))
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 